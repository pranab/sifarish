This tutorial is for social recommendation base on collaborative filtering. Processing 
is done with a  pipeline of MR jobs. Some of them are optional. All commands are in the 
shell script brec.sh. Please make necessary changes for path, environment etc in that file 
before  proceeding


Dependency Jars
===============
Please refer to resource/jar_dpendency.txt


Generating Rating data (optional)
================================
You could generate rating data directly, by following the steps here. If not 
you could generate implicit rating data as described below. The format of rating data 
generated is as follows. Each line has rating by all  users for a given item

item1,user1:3,user2:4,..
item2,user2:5,user4:2,...

You can use ratings.rb as follows to generate ratings data and save it ia file
It requires util.rb to be in the ../lib directory. You can get util.rb
from the visitante project at the following location
https://github.com/pranab/visitante/tree/master/script/ruby

1. generate explicit rating data
./brec.sh genExplicitRating <item_count> <user_count> <user_per_items_multipler>  > <rating_file>

In the output, average number of users rating for an item will be 
item_count *  user_per_items_multipler / user_count. So choose the last argument 
as per your need. User count should be an order of magnitude higher than item count. 
The value of user_per_items_multipler should be 5 or more. A reasoable value is 10

2. Copy rating data to HDFS
./brec.sh expExplicitRating <rating_file>

Implicit Rating Predictor (optiuonal)
=====================================
This MR task is optional. You want to run this MR if you want to generate rating data
from user engaement click stream data. If you have generated rating data directly from script
then skip this.

1.Export user engaement schema to HDFS
./brec.sh expSchema

2.Generate user engagement data as follows
./brec.sh genHistEvent <item_count> <user_count> <average_event_count_per_user>
average_event_count_per_user = number of events per customer (a reasonable number is around 10)

3.Copy the input data file to  HDFS input directory. This is the script to run MR
./brec.sh expEvent

4. Run MR
./brec.sh genRating


Rating data formatter (optional)
================================
If you ran ImplicitRatingPredictor, it generated rating data in an exploded format as 
userID, itemID, rating. However, Rating Correlation MR below expects data in a compact 
format as  itemID, userID1:rating1, userId2:rating2

1. Run MR
./brech.sh compactRating


Rating Statistics (optional)
============================
If the parameter input.rating.stdDev.weighted.average is set to true for UtilityAggregator,
then rating std dev calculation is necessary. In our example, we are not using it.

1. Run MR
./brec.sh ratingStat


Rating correlation
==================
Correlation can be calculated in various ways. We will be using cosine similarity.

1. Run MR
./brec.sh correlation

Rating Predictor
================
The next step is to predict rating based on items already rated by user and the correlation
calculated in the first MR

1.The rating file should be renamed so that it has the same prefix   
as defined by  the config param rating.file.prefix (prRating here). It should 
be repeated if there are multiple reducer output files
./brec.sh renameRatingFile part-r-00000 prRating0.txt 

2. The rating file should be renamed so that it has the same prefix   
as defined by  the config param rating.stat.file.prefix. It should 
be repeated if there are multiple reducer output files
./brec.sh renameRatingStat

3. Run MR as follows
./brec.sh ratingPred

Aggregate Rating Predictor
==========================
This predicts the final rating by aggregating contribution from all items rated by the user

1. Run MR
./brec.sh ratingAggr

Business Goal Injection (optional)
==================================
This is an optional MR, that combines scores of various business goals with recommendation score
using relative weighting to come up with the final score. In our example, we are not using it.

1. Copy business score data
./brec.sh expBizData

2. Run MR
./brec.sh injectBizGoal


Order by User ID (optional)
===========================
It orders the final result by userID, so that you get all recommendation for
a given user together

1. Run MR. Unsroted data dir name (not full path) needs to be specified, because
unsorted data location depends on post processing  done with predicted rating 
(e.g., business goal injection) 
./brec.sh  sortByUser <unsorted_data_hdfs_dir>


Novelty per user (optional)
===========================
Nobelty can blended in with predicted rating as follows

1. Caculate user item engaement distribution
./brec.sh genEngageDistr

2. Generate item novelty score
./brec.sh genItemNovelty

3. Rename predicted rating file to have prefix as defined in config param first.type.prefix. 
The command should be repeatedly executed  if there are multiple reducer output files
./brec.sh renamePredRatingFile  part-r-00000 prRatings0.txt

4. Join predicted rating and novelty
./brec.sh joinRatingNovelty

5. Weighted average of predicted rating and novelty
./brec.sh injectItemNovelty

Item popularity global
======================
It can be used to solve cold start problem. Popularity is calculated by taking weighted 
average of various rating stats

1. Run MR
./brec.sh itemPopularity

Configuration
=============
it's in reco.properties

 
